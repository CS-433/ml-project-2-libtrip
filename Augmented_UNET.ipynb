{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MWXJ_8ZPO_k9"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from ImageDataset import *\n",
        "from unet import *\n",
        "from loss import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8zS55cVO_k_"
      },
      "source": [
        "## Unzip The Data  \n",
        "Only if running on google colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "s6siSt82O_lB",
        "outputId": "fa7e04a8-fbb6-4b03-cdd3-1b4f4826aff5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3ca39694f0bb>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/predictions.zip'"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the uploaded zip file\n",
        "zip_path = '/content/data.zip'\n",
        "pred_path = '/predictions.zip'\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "with zipfile.ZipFile(pred_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MiyidXCsO_lC"
      },
      "outputs": [],
      "source": [
        "TRAIN_IMAGES = 'data/training/images/'\n",
        "GROUNDTRUTH = 'data/training/groundtruth/'\n",
        "TEST_IMAGES = 'data/test_set_images/'\n",
        "TRAIN_AUG_IMAGES = 'data/augmented/images_1/'\n",
        "TRAIN_AUG_IMAGES_GT = 'data/augmented/groundtruth_1/'\n",
        "AUG_IM_DATASET= 'data/augmented/images_for_train_1/'\n",
        "AUG_GT_DATASET='data/augmented/groundtruth_for_train_1/'\n",
        "\n",
        "FOREGROUND_TRESHOLD = 0.25\n",
        "SPLIT_RATIO = 0.9\n",
        "BATCH_SIZE = 10\n",
        "EPOCHS = 30\n",
        "LR = 1e-3\n",
        "SEED = 0\n",
        "WEIGHT_DECAY = 1e-3\n",
        "WORKERS = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DHmMVuEUO_lC",
        "outputId": "ade18f7d-4632-40b1-fbf2-a518fd7cbe71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "pin_memory = device == 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hdCC6pLjO_lE"
      },
      "outputs": [],
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jBS-DAD_O_lE"
      },
      "outputs": [],
      "source": [
        "dataset = ImagesDataset(\n",
        "    img_dir=TRAIN_IMAGES,\n",
        "    gt_dir=GROUNDTRUTH,\n",
        "    image_transform=image_transform,\n",
        "    mask_transform=mask_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_augmented=ImagesDataset(\n",
        "    img_dir=AUG_IM_DATASET,\n",
        "    gt_dir=AUG_GT_DATASET,\n",
        "    image_transform=image_transform,\n",
        "    mask_transform=mask_transform,\n",
        ")\n"
      ],
      "metadata": {
        "id": "3Y5gJqxQby40"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "8UVGg16rO_lE",
        "outputId": "3f533b7b-90fe-474d-9e3b-2f0df390a640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "\n",
        "len(dataset_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "IFXRzaqaO_lF",
        "outputId": "185db0c0-e7db-4010-decc-c3854a5dc889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: torch.Size([3, 400, 400])\n",
            "Mask size: torch.Size([1, 400, 400])\n"
          ]
        }
      ],
      "source": [
        "image, mask = dataset[0]\n",
        "print('Image size:', image.shape)\n",
        "print('Mask size:', mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_augmented=DataLoader(\n",
        "    dataset=dataset_augmented,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n"
      ],
      "metadata": {
        "id": "5oi2U1rt0kP5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, mask = dataset_augmented[55]\n",
        "print('Image size:', image.shape)\n",
        "print('Mask size:', mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYC5LvYv99lw",
        "outputId": "23a48aa7-88b9-440f-f1bb-921fd2a187d3"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: torch.Size([3, 400, 400])\n",
            "Mask size: torch.Size([1, 400, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DO9Xnm7TO_lG"
      },
      "outputs": [],
      "source": [
        "model= UNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QYDsbX8LO_lG"
      },
      "outputs": [],
      "source": [
        "criterion = DiceLoss()\n",
        "optimizer = Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5M7UA4qcO_lG"
      },
      "outputs": [],
      "source": [
        "# Learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    optimizer=optimizer,\n",
        "    mode='min',\n",
        "    patience=5,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hd5390eXO_lG",
        "outputId": "9e281fe0-e8cc-4b4c-833d-606f6b3eb2a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 20/20 [00:10<00:00,  1.91batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10535573959350586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 20/20 [00:10<00:00,  1.86batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10149713158607483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 20/20 [00:10<00:00,  1.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10459302663803101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 20/20 [00:10<00:00,  1.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10259484052658081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 20/20 [00:10<00:00,  1.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10229150354862213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 20/20 [00:10<00:00,  1.89batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10062060356140137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 20/20 [00:10<00:00,  1.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10092123746871948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 20/20 [00:10<00:00,  1.87batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.1025170624256134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 20/20 [00:10<00:00,  1.86batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10083956122398377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 20/20 [00:10<00:00,  1.85batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10163128972053528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 20/20 [00:11<00:00,  1.81batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.10146512687206269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 20/20 [00:10<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09886210262775422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 20/20 [00:10<00:00,  1.86batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09997643828392029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|██████████| 20/20 [00:10<00:00,  1.86batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09895168840885163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|██████████| 20/20 [00:10<00:00,  1.85batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09842074811458587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|██████████| 20/20 [00:10<00:00,  1.85batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09820108115673065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|██████████| 20/20 [00:10<00:00,  1.85batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.0987684577703476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|██████████| 20/20 [00:11<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09849398732185363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|██████████| 20/20 [00:10<00:00,  1.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09696107208728791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09808212816715241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|██████████| 20/20 [00:10<00:00,  1.85batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09601652026176452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|██████████| 20/20 [00:10<00:00,  1.85batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09800914824008941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09721019566059112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|██████████| 20/20 [00:10<00:00,  1.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09652415215969086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09514974355697632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09512695372104644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09441564679145813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|██████████| 20/20 [00:10<00:00,  1.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09520743191242217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|██████████| 20/20 [00:11<00:00,  1.80batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09341749548912048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|██████████| 20/20 [00:10<00:00,  1.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09467585384845734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|██████████| 20/20 [00:10<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09111877679824829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09127126932144165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|██████████| 20/20 [00:10<00:00,  1.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09312590956687927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|██████████| 20/20 [00:11<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09122619032859802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|██████████| 20/20 [00:11<00:00,  1.81batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09171547293663025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|██████████| 20/20 [00:10<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09161608517169953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09061440527439117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|██████████| 20/20 [00:10<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08991614878177642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09066684246063232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 20/20 [00:10<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08940918743610382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 20/20 [00:11<00:00,  1.80batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08843537867069244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 20/20 [00:10<00:00,  1.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.09185737371444702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08692256212234498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 20/20 [00:11<00:00,  1.80batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.0872274547815323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08762953877449035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08696884512901307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 20/20 [00:11<00:00,  1.81batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08719804584980011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 20/20 [00:11<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.0860293060541153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 20/20 [00:10<00:00,  1.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08531491756439209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 20/20 [00:10<00:00,  1.83batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  0.08559116423130035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Set the model in training mode\n",
        "model.train()\n",
        "\n",
        "# Define the number of training epochs\n",
        "epochs = 50  # You can adjust this as needed\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # Iterate over the training data\n",
        "    for data, target in tqdm(train_loader_augmented, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch'):\n",
        "        # Send the input to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the total loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Average loss for the epoch\n",
        "    average_loss = total_loss / len(train_loader_augmented)\n",
        "    print(f\"average loss: \", average_loss)\n",
        "\n",
        "    # Adjust learning rate if a scheduler is provided\n",
        "    if lr_scheduler is not None:\n",
        "        lr_scheduler.step(average_loss)\n",
        "\n",
        "torch.save(model.state_dict(), 'trained_model_10ep_30batch.pth')\n",
        "\n",
        "# Save the trained model\n",
        "#torch.save(model.state_dict(), 'trained_model.pth')\n",
        "\n",
        "# Now, you can use the trained model for predictions\n",
        "# For example, if you have a test DataLoader, you can do:\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     for test_data in test_data_loader:\n",
        "#         test_data = test_data.to(device)\n",
        "#         predictions = model(test_data)\n",
        "#         # Process predictions as needed based on proba_threshold\n",
        "#         # ...\n",
        "\n",
        "# Note: This is a basic example, and you might need to adapt it based on your specific requirements and dataset structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8hhNU1wO_lH"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NI3riT3kO_lH"
      },
      "outputs": [],
      "source": [
        "# Define custom transformations for satellite images\n",
        "satellite_image_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=90),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Define custom transformations for binary masks\n",
        "binary_mask_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=90),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9qPXckAPO_lI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_augmented_dataset():\n",
        "\n",
        "    # Creates directories\n",
        "    for dirname in (TRAIN_AUG_IMAGES, TRAIN_AUG_IMAGES_GT):\n",
        "        os.makedirs(dirname, exist_ok=True)\n",
        "\n",
        "    # Load the original dataset\n",
        "    images = sorted(os.listdir(TRAIN_IMAGES))\n",
        "    masks = sorted(os.listdir(GROUNDTRUTH))\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        # Get image and mask names\n",
        "        image_name = images[i]\n",
        "        mask_name = masks[i]\n",
        "\n",
        "        # Get images paths\n",
        "        image_path = os.path.join(TRAIN_IMAGES, image_name)\n",
        "        mask_path = os.path.join(GROUNDTRUTH, mask_name)\n",
        "\n",
        "        # Open images\n",
        "        image = Image.open(image_path)\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        #apply the transformations\n",
        "        image_transformed = satellite_image_transform(image)\n",
        "        mask_transformed = binary_mask_transform(mask)\n",
        "\n",
        "        # Convert tensors to PIL Images\n",
        "        image_transformed_PIL = transforms.ToPILImage()(image_transformed)\n",
        "        mask_transformed_PIL = transforms.ToPILImage()(mask_transformed)\n",
        "\n",
        "        # Save augmented images\n",
        "        filename_img = f'Image_{i+1:04d}.png'\n",
        "        filename_gd = f'gdImage_{i+1:04d}.png'\n",
        "        image_path = os.path.join(TRAIN_AUG_IMAGES, filename_img)\n",
        "        mask_path = os.path.join(TRAIN_AUG_IMAGES_GT, filename_gd)\n",
        "        image_transformed_PIL.save(image_path)\n",
        "        mask_transformed_PIL.save(mask_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create augmented dataset\n",
        "create_augmented_dataset()"
      ],
      "metadata": {
        "id": "CAwwR4SThIp5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_contents(source, destination):\n",
        "    \"\"\"\n",
        "    Copy contents from source to destination.\n",
        "\n",
        "    Parameters:\n",
        "        source (str): Path to the source directory.\n",
        "        destination (str): Path to the destination directory.\n",
        "    \"\"\"\n",
        "    for item in os.listdir(source):\n",
        "        source_path = os.path.join(source, item)\n",
        "        destination_path = os.path.join(destination, item)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "\n",
        "def create_combined_directory(directory1, directory2, combined_directory):\n",
        "    \"\"\"\n",
        "    Create a new directory with copies of contents from two directories.\n",
        "\n",
        "    Parameters:\n",
        "        directory1 (str): Path to the first directory.\n",
        "        directory2 (str): Path to the second directory.\n",
        "        combined_directory (str): Path to the new directory where contents will be copied.\n",
        "    \"\"\"\n",
        "    # Create the new directory if it doesn't exist\n",
        "    os.makedirs(combined_directory, exist_ok=True)\n",
        "\n",
        "    # Copy contents from directory1 to the combined directory\n",
        "    copy_contents(directory1, combined_directory)\n",
        "\n",
        "    # Copy contents from directory2 to the combined directory\n",
        "    copy_contents(directory2, combined_directory)\n",
        "\n"
      ],
      "metadata": {
        "id": "LBPMN1tWhiu2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_directories(directory_1, directory_2, new_directory):\n",
        "  # Create the new directory if it doesn't exist\n",
        "  os.makedirs(new_directory, exist_ok=True)\n",
        "\n",
        "  #Iterate over the contents of the first directory and move them to the new directory\n",
        "  for item in os.listdir(directory_1):\n",
        "    source = os.path.join(directory_1, item)\n",
        "    destination = os.path.join(new_directory, item)\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "  # Iterate over the contents of the second directory and move them to the new directory\n",
        "  for item in os.listdir(directory_2):\n",
        "    source = os.path.join(directory_2, item)\n",
        "    destination = os.path.join(new_directory, item)\n",
        "    shutil.move(source, destination)"
      ],
      "metadata": {
        "id": "s1G7BqXBFMXI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "merge_directories(TRAIN_AUG_IMAGES,TRAIN_IMAGES, AUG_IM_DATASET)\n",
        "merge_directories(TRAIN_AUG_IMAGES_GT,GROUNDTRUTH,AUG_GT_DATASET)\n",
        "#create_combined_directory(TRAIN_AUG_IMAGES,TRAIN_IMAGES, AUG_IM_DATASET)\n",
        "#create_combined_directory(TRAIN_AUG_IMAGES_GT,GROUNDTRUTH,AUG_GT_DATASET)\n"
      ],
      "metadata": {
        "id": "ZPS1HQj3i4Z0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atyhQag1O_lI"
      },
      "source": [
        "## Testing and submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "59DGYJkTO_lI"
      },
      "outputs": [],
      "source": [
        "test_image_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jncc0ZtYO_lI"
      },
      "outputs": [],
      "source": [
        "test_set = ImagesDataset(\n",
        "    img_dir=TEST_IMAGES,\n",
        "    image_transform=test_image_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JChxpKVuO_lJ"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(\n",
        "    dataset=test_set,\n",
        "    num_workers=WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "N3K7Y7y2O_lJ"
      },
      "outputs": [],
      "source": [
        "def _get_pred_filename(lenth_loader, index: int) -> str:\n",
        "    \"\"\"Returns the filename of the prediction.\n",
        "\n",
        "    Args:\n",
        "        index (int): index of the image in the dataset.\n",
        "\n",
        "    Returns:\n",
        "        str: filename of the prediction.\n",
        "    \"\"\"\n",
        "    if lenth_loader > 1000:\n",
        "        return f'prediction_{index + 1:04d}.png'\n",
        "    return f'prediction_{index + 1:03d}.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "oE1q5o8MO_lJ"
      },
      "outputs": [],
      "source": [
        "def _predict_labels(\n",
        "    output: torch.Tensor,\n",
        "    proba_threshold: float,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Predicts the labels for an output.\n",
        "\n",
        "    Args:\n",
        "        output (torch.Tensor): tensor output.\n",
        "        proba_threshold (float): probability threshold.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: tensor of 0 and 1.\n",
        "    \"\"\"\n",
        "    return (output > proba_threshold).type(torch.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "J7UE8bg4O_lJ"
      },
      "outputs": [],
      "source": [
        "def _save_mask(\n",
        "    output: torch.Tensor,\n",
        "    filename: str,\n",
        ") -> None:\n",
        "    \"\"\"Saves the mask as image.\n",
        "\n",
        "    Args:\n",
        "        output (torch.Tensor): tensor output.\n",
        "        filename (str): filename.\n",
        "        clean (bool, optional): True to clean the prediction using\n",
        "        postprocessing method. Defaults to True.\n",
        "    \"\"\"\n",
        "    pred_array = torch.squeeze(output * 255).cpu().numpy()\n",
        "    img = Image.fromarray(pred_array)\n",
        "    img.save(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "c2mnPc9vO_lJ"
      },
      "outputs": [],
      "source": [
        "predictions_path= 'predictions/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nNZnnHBmO_lK"
      },
      "outputs": [],
      "source": [
        "prediction_filnames = list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6zrj1YzO_lK",
        "outputId": "334a0d5d-2821-4e03-fe41-f1ebfd880669"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Run this only if you load the model\n",
        "model= UNet().to(device)\n",
        "state_dict = torch.load('models/trained_model_100ep_10batch.pth', map_location=device)\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(predictions_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "E-7KqzMOTfWp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nxlDQX27O_lK",
        "outputId": "8c5d5289-94c3-4e30-b409-403415bbf336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing prediction_001.png\n",
            "Processing prediction_002.png\n",
            "Processing prediction_003.png\n",
            "Processing prediction_004.png\n",
            "Processing prediction_005.png\n",
            "Processing prediction_006.png\n",
            "Processing prediction_007.png\n",
            "Processing prediction_008.png\n",
            "Processing prediction_009.png\n",
            "Processing prediction_010.png\n",
            "Processing prediction_011.png\n",
            "Processing prediction_012.png\n",
            "Processing prediction_013.png\n",
            "Processing prediction_014.png\n",
            "Processing prediction_015.png\n",
            "Processing prediction_016.png\n",
            "Processing prediction_017.png\n",
            "Processing prediction_018.png\n",
            "Processing prediction_019.png\n",
            "Processing prediction_020.png\n",
            "Processing prediction_021.png\n",
            "Processing prediction_022.png\n",
            "Processing prediction_023.png\n",
            "Processing prediction_024.png\n",
            "Processing prediction_025.png\n",
            "Processing prediction_026.png\n",
            "Processing prediction_027.png\n",
            "Processing prediction_028.png\n",
            "Processing prediction_029.png\n",
            "Processing prediction_030.png\n",
            "Processing prediction_031.png\n",
            "Processing prediction_032.png\n",
            "Processing prediction_033.png\n",
            "Processing prediction_034.png\n",
            "Processing prediction_035.png\n",
            "Processing prediction_036.png\n",
            "Processing prediction_037.png\n",
            "Processing prediction_038.png\n",
            "Processing prediction_039.png\n",
            "Processing prediction_040.png\n",
            "Processing prediction_041.png\n",
            "Processing prediction_042.png\n",
            "Processing prediction_043.png\n",
            "Processing prediction_044.png\n",
            "Processing prediction_045.png\n",
            "Processing prediction_046.png\n",
            "Processing prediction_047.png\n",
            "Processing prediction_048.png\n",
            "Processing prediction_049.png\n",
            "Processing prediction_050.png\n",
            "Prediction completed.\n"
          ]
        }
      ],
      "source": [
        "# Set the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Switch off autograd\n",
        "with torch.no_grad():\n",
        "    # Loop over the dataset\n",
        "    for i, (data, target) in enumerate(test_loader):\n",
        "        filename = _get_pred_filename(len(test_loader),i)\n",
        "        print(f'Processing {filename}')\n",
        "\n",
        "        # Send the input to the device\n",
        "        data = data.to(device)\n",
        "        if target.dim() != 1:\n",
        "            target = target.to(device)\n",
        "\n",
        "        # Make the predictions\n",
        "        output = model(data)\n",
        "\n",
        "        # Get labels\n",
        "        output = _predict_labels(output, 0.25)\n",
        "\n",
        "        # Save mask\n",
        "        output_path = os.path.join(predictions_path, filename)\n",
        "        _save_mask(output, output_path)\n",
        "        prediction_filnames.append(output_path)\n",
        "\n",
        "# Print a message after processing all images\n",
        "print('Prediction completed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qayc7tgyO_lK"
      },
      "outputs": [],
      "source": [
        "from helper import *\n",
        "masks_to_submission('submission1.csv', *prediction_filnames)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}