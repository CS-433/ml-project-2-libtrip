{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from ImageDataset import *\n",
    "from unet import *\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip The Data  \n",
    "Only if running on google colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the path to the uploaded zip file\n",
    "zip_path = 'data.zip'\n",
    "pred_path = 'predictions.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extract_path = '/data2/'\n",
    "extract_pred= '/predictions2/'\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "os.makedirs(extract_pred, exist_ok=True)\n",
    "with zipfile.ZipFile(pred_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES = 'data/training/images/'\n",
    "GROUNDTRUTH = 'data/training/groundtruth/'\n",
    "TEST_IMAGES = 'data/test_set_images/'\n",
    "FOREGROUND_TRESHOLD = 0.25\n",
    "SPLIT_RATIO = 0.9\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 30\n",
    "LR = 1e-3\n",
    "SEED = 0\n",
    "WEIGHT_DECAY = 1e-3\n",
    "WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "pin_memory = device == 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImagesDataset(\n",
    "    img_dir=TRAIN_IMAGES,\n",
    "    gt_dir=GROUNDTRUTH,\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([3, 400, 400])\n",
      "Mask size: torch.Size([1, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "image, mask = dataset[0]\n",
    "print('Image size:', image.shape)\n",
    "print('Mask size:', mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= UNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 10/10 [03:12<00:00, 19.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.6479327440261841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 10/10 [03:05<00:00, 18.56s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.5524351000785828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 10/10 [03:10<00:00, 19.05s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.5209612488746643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 10/10 [03:09<00:00, 18.95s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.4906199038028717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 10/10 [03:10<00:00, 19.06s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.45297694206237793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 10/10 [03:11<00:00, 19.19s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.4200475513935089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 10/10 [03:15<00:00, 19.57s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.4059355616569519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 10/10 [03:22<00:00, 20.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.3777090311050415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 10/10 [03:21<00:00, 20.15s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.3745973765850067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [03:28<00:00, 20.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.3589638650417328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# Define the number of training epochs\n",
    "epochs = 10  # You can adjust this as needed\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for data, target in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch'):\n",
    "        # Send the input to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"average loss: \", average_loss)\n",
    "\n",
    "    # Adjust learning rate if a scheduler is provided\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step(average_loss)\n",
    "\n",
    "torch.save(model.state_dict(), 'trained_model_10ep_30batch.pth')\n",
    "\n",
    "# Save the trained model\n",
    "#torch.save(model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "# Now, you can use the trained model for predictions\n",
    "# For example, if you have a test DataLoader, you can do:\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for test_data in test_data_loader:\n",
    "#         test_data = test_data.to(device)\n",
    "#         predictions = model(test_data)\n",
    "#         # Process predictions as needed based on proba_threshold\n",
    "#         # ...\n",
    "\n",
    "# Note: This is a basic example, and you might need to adapt it based on your specific requirements and dataset structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImagesDataset(\n",
    "    img_dir=TEST_IMAGES,\n",
    "    image_transform=test_image_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pred_filename(lenth_loader, index: int) -> str:\n",
    "    \"\"\"Returns the filename of the prediction.\n",
    "\n",
    "    Args:\n",
    "        index (int): index of the image in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        str: filename of the prediction.\n",
    "    \"\"\"\n",
    "    if lenth_loader > 1000:\n",
    "        return f'prediction_{index + 1:04d}.png'\n",
    "    return f'prediction_{index + 1:03d}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_labels(\n",
    "    output: torch.Tensor,\n",
    "    proba_threshold: float,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Predicts the labels for an output.\n",
    "\n",
    "    Args:\n",
    "        output (torch.Tensor): tensor output.\n",
    "        proba_threshold (float): probability threshold.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: tensor of 0 and 1.\n",
    "    \"\"\"\n",
    "    return (output > proba_threshold).type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_mask(\n",
    "    output: torch.Tensor,\n",
    "    filename: str,\n",
    ") -> None:\n",
    "    \"\"\"Saves the mask as image.\n",
    "\n",
    "    Args:\n",
    "        output (torch.Tensor): tensor output.\n",
    "        filename (str): filename.\n",
    "        clean (bool, optional): True to clean the prediction using\n",
    "        postprocessing method. Defaults to True.\n",
    "    \"\"\"\n",
    "    pred_array = torch.squeeze(output * 255).cpu().numpy()\n",
    "    img = Image.fromarray(pred_array)\n",
    "    img.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path= 'predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_filnames = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this only if you load the model\n",
    "model= UNet().to(device)\n",
    "state_dict = torch.load('models/trained_model_100ep_10batch.pth', map_location=device)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prediction_001.png\n",
      "Processing prediction_002.png\n",
      "Processing prediction_003.png\n",
      "Processing prediction_004.png\n",
      "Processing prediction_005.png\n",
      "Processing prediction_006.png\n",
      "Processing prediction_007.png\n",
      "Processing prediction_008.png\n",
      "Processing prediction_009.png\n",
      "Processing prediction_010.png\n",
      "Processing prediction_011.png\n",
      "Processing prediction_012.png\n",
      "Processing prediction_013.png\n",
      "Processing prediction_014.png\n",
      "Processing prediction_015.png\n",
      "Processing prediction_016.png\n",
      "Processing prediction_017.png\n",
      "Processing prediction_018.png\n",
      "Processing prediction_019.png\n",
      "Processing prediction_020.png\n",
      "Processing prediction_021.png\n",
      "Processing prediction_022.png\n",
      "Processing prediction_023.png\n",
      "Processing prediction_024.png\n",
      "Processing prediction_025.png\n",
      "Processing prediction_026.png\n",
      "Processing prediction_027.png\n",
      "Processing prediction_028.png\n",
      "Processing prediction_029.png\n",
      "Processing prediction_030.png\n",
      "Processing prediction_031.png\n",
      "Processing prediction_032.png\n",
      "Processing prediction_033.png\n",
      "Processing prediction_034.png\n",
      "Processing prediction_035.png\n",
      "Processing prediction_036.png\n",
      "Processing prediction_037.png\n",
      "Processing prediction_038.png\n",
      "Processing prediction_039.png\n",
      "Processing prediction_040.png\n",
      "Processing prediction_041.png\n",
      "Processing prediction_042.png\n",
      "Processing prediction_043.png\n",
      "Processing prediction_044.png\n",
      "Processing prediction_045.png\n",
      "Processing prediction_046.png\n",
      "Processing prediction_047.png\n",
      "Processing prediction_048.png\n",
      "Processing prediction_049.png\n",
      "Processing prediction_050.png\n",
      "Prediction completed.\n"
     ]
    }
   ],
   "source": [
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Switch off autograd\n",
    "with torch.no_grad():\n",
    "    # Loop over the dataset\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        filename = _get_pred_filename(len(test_loader),i)\n",
    "        print(f'Processing {filename}')\n",
    "\n",
    "        # Send the input to the device\n",
    "        data = data.to(device)\n",
    "        if target.dim() != 1:\n",
    "            target = target.to(device)\n",
    "\n",
    "        # Make the predictions\n",
    "        output = model(data)\n",
    "\n",
    "        # Get labels\n",
    "        output = _predict_labels(output, 0.25)\n",
    "\n",
    "        # Save mask\n",
    "        output_path = os.path.join(predictions_path, filename)\n",
    "        _save_mask(output, output_path)\n",
    "        prediction_filnames.append(output_path)\n",
    "\n",
    "# Print a message after processing all images\n",
    "print('Prediction completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "masks_to_submission('submission.csv', *prediction_filnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
